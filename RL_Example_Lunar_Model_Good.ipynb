{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec84f8d",
   "metadata": {},
   "source": [
    "# Works only with Python 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e4748e",
   "metadata": {},
   "source": [
    "#### Overview:\n",
    "    1.Stable Baselines\n",
    "    2.Training RL model using ACER\n",
    "    3.Running and evaluating a Stable Baslines RL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea95bcb",
   "metadata": {},
   "source": [
    "#### The main goal of the lunar lander example that tries to land a spaceship on the surface of the moon\n",
    "The goal is to direct the jets on the spaceship so that it is able to land in between the flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8662bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/acr/Documents/Jupyter Notebook\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd /home/acr/Documents/Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1efa86",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3464887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (3.19.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.12.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.20.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.16.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (0.37.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: h5py in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (58.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-gpu==1.15.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.42.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.20.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (0.37.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (3.19.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.15.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: h5py in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (58.0.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.10.0.2)\n",
      "Requirement already satisfied: stable_baselines in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (2.10.2)\n",
      "Requirement already satisfied: matplotlib in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (3.4.3)\n",
      "Requirement already satisfied: numpy in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (1.20.3)\n",
      "Requirement already satisfied: joblib in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (1.1.0)\n",
      "Requirement already satisfied: opencv-python in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (4.5.4.60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (1.7.1)\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (0.21.0)\n",
      "Requirement already satisfied: pandas in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (1.3.4)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from stable_baselines) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (4.8.1)\n",
      "Requirement already satisfied: ale-py~=0.7.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (0.7.3)\n",
      "Requirement already satisfied: pyglet>=1.4.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (1.5.21)\n",
      "Requirement already satisfied: importlib-resources in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from ale-py~=0.7.1->gym[atari,classic_control]>=0.11->stable_baselines) (5.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym[atari,classic_control]>=0.11->stable_baselines) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym[atari,classic_control]>=0.11->stable_baselines) (3.10.0.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from matplotlib->stable_baselines) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from matplotlib->stable_baselines) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from matplotlib->stable_baselines) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from matplotlib->stable_baselines) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from matplotlib->stable_baselines) (2.8.2)\n",
      "Requirement already satisfied: six in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->stable_baselines) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from pandas->stable_baselines) (2021.3)\n",
      "Requirement already satisfied: gym in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from gym) (1.20.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from gym) (4.8.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/acr/anaconda3/envs/p37workshop/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym) (3.6.0)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: box2d-py in /home/acr/.local/lib/python3.7/site-packages (2.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15 \n",
    "!pip install tensorflow-gpu==1.15.0 \n",
    "!pip install stable_baselines \n",
    "!pip install gym\n",
    "!conda install swig -y # needed to build Box2D in the pip install\n",
    "!pip install box2d-py # a repackaged version of pybox2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b5cc0db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "from stable_baselines import ACER\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e36f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"LunarLander-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559b3d7",
   "metadata": {},
   "source": [
    "# 1. Test Random Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dd708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c825cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score: -422.84819252014483\n",
      "Episode:2 Score: -164.69699791550406\n",
      "Episode:3 Score: -357.3116728070553\n",
      "Episode:4 Score: -103.42492749717834\n",
      "Episode:5 Score: -131.75169804037608\n",
      "Episode:6 Score: -158.62803100321838\n",
      "Episode:7 Score: -378.9386237445764\n",
      "Episode:8 Score: -79.46534265696158\n",
      "Episode:9 Score: -212.40220932075215\n",
      "Episode:10 Score: -139.0497339989762\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1,episodes+1):\n",
    "  state=env.reset()\n",
    "  done=False\n",
    "  score=0\n",
    "\n",
    "  while not done:\n",
    "    env.render()\n",
    "    time.sleep(0.009) # Slowing the rendering. It stops 0.009 seconds for each frame\n",
    "    action = env.action_space.sample() # 0 and 1 represent movements like right and left\n",
    "    n_state, reward, done, info = env.step(action)\n",
    "    score+=reward\n",
    "  print('Episode:{} Score: {}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa443d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bef10d",
   "metadata": {},
   "source": [
    "# 2. Build and Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ec4333",
   "metadata": {},
   "source": [
    "#### We'll be building and training the model using stable baselines' algorithms to train a RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1cfcee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env=gym.make(environment_name) # Creating the environment\n",
    "env=DummyVecEnv([lambda: env]) # Wrap our environment inside of the dummy vec environment\n",
    "model = ACER('MlpPolicy', env, verbose=1) # The first element defines the neural network, which is MultiLayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79c46f53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 8.65e-12 |\n",
      "| avg_norm_g          | 5.27     |\n",
      "| avg_norm_grads_f    | 5.27     |\n",
      "| avg_norm_k          | 3.79e+05 |\n",
      "| avg_norm_k_dot_g    | 1.98     |\n",
      "| entropy             | 3.31     |\n",
      "| explained_variance  | -2.41    |\n",
      "| fps                 | 0        |\n",
      "| loss                | 6.71     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.355   |\n",
      "| loss_policy         | -0.355   |\n",
      "| loss_q              | 14.2     |\n",
      "| mean_episode_length | 0        |\n",
      "| mean_episode_reward | 0        |\n",
      "| norm_grads          | 77.2     |\n",
      "| norm_grads_policy   | 4.46     |\n",
      "| norm_grads_q        | 77.1     |\n",
      "| total_timesteps     | 20       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.267    |\n",
      "| avg_norm_g          | 4.91     |\n",
      "| avg_norm_grads_f    | 4.6      |\n",
      "| avg_norm_k          | 26.1     |\n",
      "| avg_norm_k_dot_g    | 4.46     |\n",
      "| entropy             | 12.4     |\n",
      "| explained_variance  | -0.16    |\n",
      "| fps                 | 300      |\n",
      "| loss                | 1.93     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.27    |\n",
      "| loss_policy         | -1.27    |\n",
      "| loss_q              | 6.64     |\n",
      "| mean_episode_length | 320      |\n",
      "| mean_episode_reward | -138     |\n",
      "| norm_grads          | 52       |\n",
      "| norm_grads_policy   | 25.3     |\n",
      "| norm_grads_q        | 45.4     |\n",
      "| total_timesteps     | 2020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 5.69     |\n",
      "| avg_norm_grads_f    | 5.69     |\n",
      "| avg_norm_k          | 2.27     |\n",
      "| avg_norm_k_dot_g    | 6.49     |\n",
      "| entropy             | 10.3     |\n",
      "| explained_variance  | 0.81     |\n",
      "| fps                 | 328      |\n",
      "| loss                | 1.75     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.961    |\n",
      "| loss_policy         | 0.961    |\n",
      "| loss_q              | 1.79     |\n",
      "| mean_episode_length | 274      |\n",
      "| mean_episode_reward | -130     |\n",
      "| norm_grads          | 20.3     |\n",
      "| norm_grads_policy   | 9.59     |\n",
      "| norm_grads_q        | 17.9     |\n",
      "| total_timesteps     | 4020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.00507  |\n",
      "| avg_norm_g          | 1.39     |\n",
      "| avg_norm_grads_f    | 1.39     |\n",
      "| avg_norm_k          | 2.32     |\n",
      "| avg_norm_k_dot_g    | 1.69     |\n",
      "| entropy             | 10.1     |\n",
      "| explained_variance  | 0.347    |\n",
      "| fps                 | 307      |\n",
      "| loss                | 0.182    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.105    |\n",
      "| loss_policy         | 0.105    |\n",
      "| loss_q              | 0.356    |\n",
      "| mean_episode_length | 296      |\n",
      "| mean_episode_reward | -124     |\n",
      "| norm_grads          | 5.56     |\n",
      "| norm_grads_policy   | 3.5      |\n",
      "| norm_grads_q        | 4.31     |\n",
      "| total_timesteps     | 6020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0442   |\n",
      "| avg_norm_g          | 1.47     |\n",
      "| avg_norm_grads_f    | 1.44     |\n",
      "| avg_norm_k          | 2.43     |\n",
      "| avg_norm_k_dot_g    | 1.44     |\n",
      "| entropy             | 13.3     |\n",
      "| explained_variance  | 0.0542   |\n",
      "| fps                 | 311      |\n",
      "| loss                | 0.145    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.0504  |\n",
      "| loss_policy         | -0.0504  |\n",
      "| loss_q              | 0.656    |\n",
      "| mean_episode_length | 349      |\n",
      "| mean_episode_reward | -122     |\n",
      "| norm_grads          | 6.3      |\n",
      "| norm_grads_policy   | 6.23     |\n",
      "| norm_grads_q        | 0.889    |\n",
      "| total_timesteps     | 8020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.82     |\n",
      "| avg_norm_g          | 4.01     |\n",
      "| avg_norm_grads_f    | 2.34     |\n",
      "| avg_norm_k          | 1.68     |\n",
      "| avg_norm_k_dot_g    | 3.43     |\n",
      "| entropy             | 7.23     |\n",
      "| explained_variance  | -2.54    |\n",
      "| fps                 | 287      |\n",
      "| loss                | 2.56     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.539   |\n",
      "| loss_policy         | -0.539   |\n",
      "| loss_q              | 6.33     |\n",
      "| mean_episode_length | 396      |\n",
      "| mean_episode_reward | -123     |\n",
      "| norm_grads          | 47.1     |\n",
      "| norm_grads_policy   | 14.7     |\n",
      "| norm_grads_q        | 44.8     |\n",
      "| total_timesteps     | 10020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 14.8     |\n",
      "| avg_norm_g          | 54       |\n",
      "| avg_norm_grads_f    | 46       |\n",
      "| avg_norm_k          | 1.31     |\n",
      "| avg_norm_k_dot_g    | 37.8     |\n",
      "| entropy             | 3.38     |\n",
      "| explained_variance  | 0.767    |\n",
      "| fps                 | 296      |\n",
      "| loss                | 405      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -11.7    |\n",
      "| loss_policy         | -11.7    |\n",
      "| loss_q              | 834      |\n",
      "| mean_episode_length | 387      |\n",
      "| mean_episode_reward | -123     |\n",
      "| norm_grads          | 421      |\n",
      "| norm_grads_policy   | 254      |\n",
      "| norm_grads_q        | 337      |\n",
      "| total_timesteps     | 12020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.328    |\n",
      "| avg_norm_g          | 2.25     |\n",
      "| avg_norm_grads_f    | 2.04     |\n",
      "| avg_norm_k          | 2.19     |\n",
      "| avg_norm_k_dot_g    | 2.26     |\n",
      "| entropy             | 8.6      |\n",
      "| explained_variance  | -1.88    |\n",
      "| fps                 | 280      |\n",
      "| loss                | 0.506    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.429   |\n",
      "| loss_policy         | -0.429   |\n",
      "| loss_q              | 2.04     |\n",
      "| mean_episode_length | 400      |\n",
      "| mean_episode_reward | -120     |\n",
      "| norm_grads          | 18.1     |\n",
      "| norm_grads_policy   | 6.72     |\n",
      "| norm_grads_q        | 16.8     |\n",
      "| total_timesteps     | 14020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.724    |\n",
      "| avg_norm_g          | 4.61     |\n",
      "| avg_norm_grads_f    | 4.05     |\n",
      "| avg_norm_k          | 5.08     |\n",
      "| avg_norm_k_dot_g    | 3.92     |\n",
      "| entropy             | 10.9     |\n",
      "| explained_variance  | 0.0532   |\n",
      "| fps                 | 275      |\n",
      "| loss                | 0.463    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.1     |\n",
      "| loss_policy         | -1.1     |\n",
      "| loss_q              | 3.34     |\n",
      "| mean_episode_length | 416      |\n",
      "| mean_episode_reward | -116     |\n",
      "| norm_grads          | 35.7     |\n",
      "| norm_grads_policy   | 9.01     |\n",
      "| norm_grads_q        | 34.5     |\n",
      "| total_timesteps     | 16020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0732   |\n",
      "| avg_norm_g          | 1.4      |\n",
      "| avg_norm_grads_f    | 1.27     |\n",
      "| avg_norm_k          | 4.67     |\n",
      "| avg_norm_k_dot_g    | 1.32     |\n",
      "| entropy             | 11       |\n",
      "| explained_variance  | -0.344   |\n",
      "| fps                 | 273      |\n",
      "| loss                | 0.0336   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.133   |\n",
      "| loss_policy         | -0.133   |\n",
      "| loss_q              | 0.553    |\n",
      "| mean_episode_length | 413      |\n",
      "| mean_episode_reward | -113     |\n",
      "| norm_grads          | 3.44     |\n",
      "| norm_grads_policy   | 2.4      |\n",
      "| norm_grads_q        | 2.47     |\n",
      "| total_timesteps     | 18020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.16     |\n",
      "| avg_norm_g          | 3.46     |\n",
      "| avg_norm_grads_f    | 2.44     |\n",
      "| avg_norm_k          | 2.22     |\n",
      "| avg_norm_k_dot_g    | 3.83     |\n",
      "| entropy             | 7.69     |\n",
      "| explained_variance  | -0.274   |\n",
      "| fps                 | 264      |\n",
      "| loss                | 1.65     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.532   |\n",
      "| loss_policy         | -0.532   |\n",
      "| loss_q              | 4.53     |\n",
      "| mean_episode_length | 456      |\n",
      "| mean_episode_reward | -108     |\n",
      "| norm_grads          | 27.5     |\n",
      "| norm_grads_policy   | 11.9     |\n",
      "| norm_grads_q        | 24.8     |\n",
      "| total_timesteps     | 20020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.494    |\n",
      "| avg_norm_g          | 3.04     |\n",
      "| avg_norm_grads_f    | 2.57     |\n",
      "| avg_norm_k          | 3.22     |\n",
      "| avg_norm_k_dot_g    | 3.01     |\n",
      "| entropy             | 9.28     |\n",
      "| explained_variance  | 0.103    |\n",
      "| fps                 | 256      |\n",
      "| loss                | 1.66     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.551   |\n",
      "| loss_policy         | -0.551   |\n",
      "| loss_q              | 4.6      |\n",
      "| mean_episode_length | 485      |\n",
      "| mean_episode_reward | -102     |\n",
      "| norm_grads          | 37       |\n",
      "| norm_grads_policy   | 5.81     |\n",
      "| norm_grads_q        | 36.5     |\n",
      "| total_timesteps     | 22020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0.84     |\n",
      "| avg_norm_g          | 10.4     |\n",
      "| avg_norm_grads_f    | 9.86     |\n",
      "| avg_norm_k          | 3.52     |\n",
      "| avg_norm_k_dot_g    | 10.7     |\n",
      "| entropy             | 8.56     |\n",
      "| explained_variance  | 0.321    |\n",
      "| fps                 | 252      |\n",
      "| loss                | 0.576    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.25    |\n",
      "| loss_policy         | -1.25    |\n",
      "| loss_q              | 3.83     |\n",
      "| mean_episode_length | 520      |\n",
      "| mean_episode_reward | -102     |\n",
      "| norm_grads          | 74.5     |\n",
      "| norm_grads_policy   | 14.4     |\n",
      "| norm_grads_q        | 73.1     |\n",
      "| total_timesteps     | 24020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0935   |\n",
      "| avg_norm_g          | 8.36     |\n",
      "| avg_norm_grads_f    | 8.24     |\n",
      "| avg_norm_k          | 5.56     |\n",
      "| avg_norm_k_dot_g    | 37.9     |\n",
      "| entropy             | 7.77     |\n",
      "| explained_variance  | 0.544    |\n",
      "| fps                 | 255      |\n",
      "| loss                | 0.133    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.108   |\n",
      "| loss_policy         | -0.108   |\n",
      "| loss_q              | 0.638    |\n",
      "| mean_episode_length | 523      |\n",
      "| mean_episode_reward | -97.9    |\n",
      "| norm_grads          | 10.1     |\n",
      "| norm_grads_policy   | 9.64     |\n",
      "| norm_grads_q        | 3.08     |\n",
      "| total_timesteps     | 26020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.28     |\n",
      "| avg_norm_g          | 2.59     |\n",
      "| avg_norm_grads_f    | 2.37     |\n",
      "| avg_norm_k          | 2.64     |\n",
      "| avg_norm_k_dot_g    | 2.66     |\n",
      "| entropy             | 11       |\n",
      "| explained_variance  | 0.416    |\n",
      "| fps                 | 255      |\n",
      "| loss                | 0.1      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.428   |\n",
      "| loss_policy         | -0.428   |\n",
      "| loss_q              | 1.28     |\n",
      "| mean_episode_length | 565      |\n",
      "| mean_episode_reward | -95.6    |\n",
      "| norm_grads          | 10.3     |\n",
      "| norm_grads_policy   | 7.14     |\n",
      "| norm_grads_q        | 7.36     |\n",
      "| total_timesteps     | 28020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.632    |\n",
      "| avg_norm_g          | 4.37     |\n",
      "| avg_norm_grads_f    | 3.87     |\n",
      "| avg_norm_k          | 2.42     |\n",
      "| avg_norm_k_dot_g    | 4.92     |\n",
      "| entropy             | 8.73     |\n",
      "| explained_variance  | -1.04    |\n",
      "| fps                 | 255      |\n",
      "| loss                | 0.815    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.815   |\n",
      "| loss_policy         | -0.815   |\n",
      "| loss_q              | 3.43     |\n",
      "| mean_episode_length | 568      |\n",
      "| mean_episode_reward | -95.2    |\n",
      "| norm_grads          | 51.3     |\n",
      "| norm_grads_policy   | 9.65     |\n",
      "| norm_grads_q        | 50.4     |\n",
      "| total_timesteps     | 30020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 4.95     |\n",
      "| avg_norm_grads_f    | 4.95     |\n",
      "| avg_norm_k          | 1.84     |\n",
      "| avg_norm_k_dot_g    | 4.72     |\n",
      "| entropy             | 8.81     |\n",
      "| explained_variance  | 0.454    |\n",
      "| fps                 | 255      |\n",
      "| loss                | 3.81     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.977    |\n",
      "| loss_policy         | 0.977    |\n",
      "| loss_q              | 5.85     |\n",
      "| mean_episode_length | 596      |\n",
      "| mean_episode_reward | -95.4    |\n",
      "| norm_grads          | 31       |\n",
      "| norm_grads_policy   | 9.85     |\n",
      "| norm_grads_q        | 29.4     |\n",
      "| total_timesteps     | 32020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 4.44     |\n",
      "| avg_norm_g          | 29.5     |\n",
      "| avg_norm_grads_f    | 19.7     |\n",
      "| avg_norm_k          | 3.18     |\n",
      "| avg_norm_k_dot_g    | 101      |\n",
      "| entropy             | 6.8      |\n",
      "| explained_variance  | -0.316   |\n",
      "| fps                 | 252      |\n",
      "| loss                | -0.446   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.54    |\n",
      "| loss_policy         | -1.54    |\n",
      "| loss_q              | 2.33     |\n",
      "| mean_episode_length | 594      |\n",
      "| mean_episode_reward | -92.4    |\n",
      "| norm_grads          | 21.7     |\n",
      "| norm_grads_policy   | 14.2     |\n",
      "| norm_grads_q        | 16.4     |\n",
      "| total_timesteps     | 34020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0109   |\n",
      "| avg_norm_g          | 1.34     |\n",
      "| avg_norm_grads_f    | 1.33     |\n",
      "| avg_norm_k          | 5.17     |\n",
      "| avg_norm_k_dot_g    | 1.27     |\n",
      "| entropy             | 9.45     |\n",
      "| explained_variance  | 0.261    |\n",
      "| fps                 | 252      |\n",
      "| loss                | 0.396    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.14     |\n",
      "| loss_policy         | 0.14     |\n",
      "| loss_q              | 0.702    |\n",
      "| mean_episode_length | 615      |\n",
      "| mean_episode_reward | -89.9    |\n",
      "| norm_grads          | 6.95     |\n",
      "| norm_grads_policy   | 4.43     |\n",
      "| norm_grads_q        | 5.35     |\n",
      "| total_timesteps     | 36020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.21     |\n",
      "| avg_norm_g          | 2.14     |\n",
      "| avg_norm_grads_f    | 2.05     |\n",
      "| avg_norm_k          | 11.3     |\n",
      "| avg_norm_k_dot_g    | 2.33     |\n",
      "| entropy             | 7.69     |\n",
      "| explained_variance  | 0.479    |\n",
      "| fps                 | 255      |\n",
      "| loss                | 0.4      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.018    |\n",
      "| loss_policy         | 0.018    |\n",
      "| loss_q              | 0.918    |\n",
      "| mean_episode_length | 592      |\n",
      "| mean_episode_reward | -92.2    |\n",
      "| norm_grads          | 9.87     |\n",
      "| norm_grads_policy   | 8.72     |\n",
      "| norm_grads_q        | 4.62     |\n",
      "| total_timesteps     | 38020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.503    |\n",
      "| avg_norm_g          | 2.85     |\n",
      "| avg_norm_grads_f    | 2.54     |\n",
      "| avg_norm_k          | 2.03     |\n",
      "| avg_norm_k_dot_g    | 2.82     |\n",
      "| entropy             | 9.76     |\n",
      "| explained_variance  | -0.349   |\n",
      "| fps                 | 255      |\n",
      "| loss                | 0.762    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.384   |\n",
      "| loss_policy         | -0.384   |\n",
      "| loss_q              | 2.49     |\n",
      "| mean_episode_length | 600      |\n",
      "| mean_episode_reward | -94.4    |\n",
      "| norm_grads          | 23.8     |\n",
      "| norm_grads_policy   | 10.2     |\n",
      "| norm_grads_q        | 21.5     |\n",
      "| total_timesteps     | 40020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.165    |\n",
      "| avg_norm_g          | 1.32     |\n",
      "| avg_norm_grads_f    | 1.2      |\n",
      "| avg_norm_k          | 2.24     |\n",
      "| avg_norm_k_dot_g    | 1.36     |\n",
      "| entropy             | 8.06     |\n",
      "| explained_variance  | 0.509    |\n",
      "| fps                 | 253      |\n",
      "| loss                | 0.108    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.214   |\n",
      "| loss_policy         | -0.214   |\n",
      "| loss_q              | 0.805    |\n",
      "| mean_episode_length | 634      |\n",
      "| mean_episode_reward | -94.9    |\n",
      "| norm_grads          | 8.82     |\n",
      "| norm_grads_policy   | 3.07     |\n",
      "| norm_grads_q        | 8.27     |\n",
      "| total_timesteps     | 42020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 3.18     |\n",
      "| avg_norm_grads_f    | 3.18     |\n",
      "| avg_norm_k          | 3.07     |\n",
      "| avg_norm_k_dot_g    | 3.11     |\n",
      "| entropy             | 9.96     |\n",
      "| explained_variance  | -0.461   |\n",
      "| fps                 | 252      |\n",
      "| loss                | 1.97     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.714    |\n",
      "| loss_policy         | 0.714    |\n",
      "| loss_q              | 2.72     |\n",
      "| mean_episode_length | 653      |\n",
      "| mean_episode_reward | -93.8    |\n",
      "| norm_grads          | 33.7     |\n",
      "| norm_grads_policy   | 12.7     |\n",
      "| norm_grads_q        | 31.2     |\n",
      "| total_timesteps     | 44020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.585    |\n",
      "| avg_norm_g          | 5.65     |\n",
      "| avg_norm_grads_f    | 5.27     |\n",
      "| avg_norm_k          | 5.58     |\n",
      "| avg_norm_k_dot_g    | 4.7      |\n",
      "| entropy             | 9.13     |\n",
      "| explained_variance  | -0.826   |\n",
      "| fps                 | 252      |\n",
      "| loss                | 2.41     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.942   |\n",
      "| loss_policy         | -0.942   |\n",
      "| loss_q              | 6.89     |\n",
      "| mean_episode_length | 694      |\n",
      "| mean_episode_reward | -91.8    |\n",
      "| norm_grads          | 80.7     |\n",
      "| norm_grads_policy   | 7.32     |\n",
      "| norm_grads_q        | 80.3     |\n",
      "| total_timesteps     | 46020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0.465    |\n",
      "| avg_norm_g          | 3.16     |\n",
      "| avg_norm_grads_f    | 2.89     |\n",
      "| avg_norm_k          | 1.81     |\n",
      "| avg_norm_k_dot_g    | 2.93     |\n",
      "| entropy             | 8.75     |\n",
      "| explained_variance  | 0.741    |\n",
      "| fps                 | 254      |\n",
      "| loss                | -0.354   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.677   |\n",
      "| loss_policy         | -0.677   |\n",
      "| loss_q              | 0.821    |\n",
      "| mean_episode_length | 679      |\n",
      "| mean_episode_reward | -94.5    |\n",
      "| norm_grads          | 17.1     |\n",
      "| norm_grads_policy   | 7.68     |\n",
      "| norm_grads_q        | 15.3     |\n",
      "| total_timesteps     | 48020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0887   |\n",
      "| avg_norm_g          | 10.7     |\n",
      "| avg_norm_grads_f    | 10.6     |\n",
      "| avg_norm_k          | 3.75     |\n",
      "| avg_norm_k_dot_g    | 11.2     |\n",
      "| entropy             | 9.45     |\n",
      "| explained_variance  | -0.32    |\n",
      "| fps                 | 253      |\n",
      "| loss                | 6.55     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 2.13     |\n",
      "| loss_policy         | 2.13     |\n",
      "| loss_q              | 9.03     |\n",
      "| mean_episode_length | 673      |\n",
      "| mean_episode_reward | -98.7    |\n",
      "| norm_grads          | 68.5     |\n",
      "| norm_grads_policy   | 27.7     |\n",
      "| norm_grads_q        | 62.6     |\n",
      "| total_timesteps     | 50020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 4.76     |\n",
      "| avg_norm_grads_f    | 4.76     |\n",
      "| avg_norm_k          | 3.36     |\n",
      "| avg_norm_k_dot_g    | 3.91     |\n",
      "| entropy             | 9.82     |\n",
      "| explained_variance  | 0.601    |\n",
      "| fps                 | 252      |\n",
      "| loss                | 4.58     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.901    |\n",
      "| loss_policy         | 0.901    |\n",
      "| loss_q              | 7.54     |\n",
      "| mean_episode_length | 660      |\n",
      "| mean_episode_reward | -108     |\n",
      "| norm_grads          | 51.3     |\n",
      "| norm_grads_policy   | 18.3     |\n",
      "| norm_grads_q        | 47.9     |\n",
      "| total_timesteps     | 52020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.17     |\n",
      "| avg_norm_g          | 2.08     |\n",
      "| avg_norm_grads_f    | 1.97     |\n",
      "| avg_norm_k          | 1.93     |\n",
      "| avg_norm_k_dot_g    | 2.11     |\n",
      "| entropy             | 8.47     |\n",
      "| explained_variance  | 0.236    |\n",
      "| fps                 | 252      |\n",
      "| loss                | 0.271    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.0594   |\n",
      "| loss_policy         | 0.0594   |\n",
      "| loss_q              | 0.593    |\n",
      "| mean_episode_length | 694      |\n",
      "| mean_episode_reward | -113     |\n",
      "| norm_grads          | 8.88     |\n",
      "| norm_grads_policy   | 8.43     |\n",
      "| norm_grads_q        | 2.79     |\n",
      "| total_timesteps     | 54020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.703    |\n",
      "| avg_norm_g          | 6.05     |\n",
      "| avg_norm_grads_f    | 5.56     |\n",
      "| avg_norm_k          | 1.93     |\n",
      "| avg_norm_k_dot_g    | 6.65     |\n",
      "| entropy             | 9.36     |\n",
      "| explained_variance  | -0.0278  |\n",
      "| fps                 | 252      |\n",
      "| loss                | 1.8      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.203    |\n",
      "| loss_policy         | 0.203    |\n",
      "| loss_q              | 3.38     |\n",
      "| mean_episode_length | 673      |\n",
      "| mean_episode_reward | -121     |\n",
      "| norm_grads          | 24.8     |\n",
      "| norm_grads_policy   | 19.9     |\n",
      "| norm_grads_q        | 14.8     |\n",
      "| total_timesteps     | 56020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 3.2      |\n",
      "| avg_norm_grads_f    | 3.2      |\n",
      "| avg_norm_k          | 1.88     |\n",
      "| avg_norm_k_dot_g    | 2.99     |\n",
      "| entropy             | 9.13     |\n",
      "| explained_variance  | 0.208    |\n",
      "| fps                 | 253      |\n",
      "| loss                | 1.83     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.685    |\n",
      "| loss_policy         | 0.685    |\n",
      "| loss_q              | 2.47     |\n",
      "| mean_episode_length | 622      |\n",
      "| mean_episode_reward | -123     |\n",
      "| norm_grads          | 28.9     |\n",
      "| norm_grads_policy   | 2.96     |\n",
      "| norm_grads_q        | 28.8     |\n",
      "| total_timesteps     | 58020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.25     |\n",
      "| avg_norm_g          | 14.3     |\n",
      "| avg_norm_grads_f    | 12.4     |\n",
      "| avg_norm_k          | 2        |\n",
      "| avg_norm_k_dot_g    | 12.4     |\n",
      "| entropy             | 9.17     |\n",
      "| explained_variance  | -0.75    |\n",
      "| fps                 | 251      |\n",
      "| loss                | 4.54     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -3.3     |\n",
      "| loss_policy         | -3.3     |\n",
      "| loss_q              | 15.9     |\n",
      "| mean_episode_length | 622      |\n",
      "| mean_episode_reward | -122     |\n",
      "| norm_grads          | 155      |\n",
      "| norm_grads_policy   | 58.4     |\n",
      "| norm_grads_q        | 144      |\n",
      "| total_timesteps     | 60020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 2.1      |\n",
      "| avg_norm_grads_f    | 2.1      |\n",
      "| avg_norm_k          | 2.09     |\n",
      "| avg_norm_k_dot_g    | 2.02     |\n",
      "| entropy             | 6.75     |\n",
      "| explained_variance  | 0.68     |\n",
      "| fps                 | 250      |\n",
      "| loss                | 0.864    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.309    |\n",
      "| loss_policy         | 0.309    |\n",
      "| loss_q              | 1.24     |\n",
      "| mean_episode_length | 633      |\n",
      "| mean_episode_reward | -122     |\n",
      "| norm_grads          | 11.8     |\n",
      "| norm_grads_policy   | 1.02     |\n",
      "| norm_grads_q        | 11.7     |\n",
      "| total_timesteps     | 62020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0268   |\n",
      "| avg_norm_g          | 3.16     |\n",
      "| avg_norm_grads_f    | 3.14     |\n",
      "| avg_norm_k          | 2.29     |\n",
      "| avg_norm_k_dot_g    | 2.82     |\n",
      "| entropy             | 7.32     |\n",
      "| explained_variance  | 0.829    |\n",
      "| fps                 | 249      |\n",
      "| loss                | 2.6      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.295    |\n",
      "| loss_policy         | 0.295    |\n",
      "| loss_q              | 4.75     |\n",
      "| mean_episode_length | 683      |\n",
      "| mean_episode_reward | -121     |\n",
      "| norm_grads          | 44.1     |\n",
      "| norm_grads_policy   | 16.2     |\n",
      "| norm_grads_q        | 41       |\n",
      "| total_timesteps     | 64020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0161   |\n",
      "| avg_norm_g          | 1.84     |\n",
      "| avg_norm_grads_f    | 1.82     |\n",
      "| avg_norm_k          | 4.07     |\n",
      "| avg_norm_k_dot_g    | 2.43     |\n",
      "| entropy             | 7.93     |\n",
      "| explained_variance  | 0.659    |\n",
      "| fps                 | 247      |\n",
      "| loss                | 0.771    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.195    |\n",
      "| loss_policy         | 0.195    |\n",
      "| loss_q              | 1.31     |\n",
      "| mean_episode_length | 715      |\n",
      "| mean_episode_reward | -124     |\n",
      "| norm_grads          | 13.4     |\n",
      "| norm_grads_policy   | 2.67     |\n",
      "| norm_grads_q        | 13.1     |\n",
      "| total_timesteps     | 66020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0157   |\n",
      "| avg_norm_g          | 10.5     |\n",
      "| avg_norm_grads_f    | 10.5     |\n",
      "| avg_norm_k          | 1.62     |\n",
      "| avg_norm_k_dot_g    | 8.12     |\n",
      "| entropy             | 8.17     |\n",
      "| explained_variance  | -0.0336  |\n",
      "| fps                 | 245      |\n",
      "| loss                | 2.72     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.4      |\n",
      "| loss_policy         | 1.4      |\n",
      "| loss_q              | 2.81     |\n",
      "| mean_episode_length | 713      |\n",
      "| mean_episode_reward | -122     |\n",
      "| norm_grads          | 46.7     |\n",
      "| norm_grads_policy   | 39.2     |\n",
      "| norm_grads_q        | 25.3     |\n",
      "| total_timesteps     | 68020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.638    |\n",
      "| avg_norm_g          | 4.35     |\n",
      "| avg_norm_grads_f    | 3.9      |\n",
      "| avg_norm_k          | 3.28     |\n",
      "| avg_norm_k_dot_g    | 2.79     |\n",
      "| entropy             | 8.56     |\n",
      "| explained_variance  | 0.0137   |\n",
      "| fps                 | 247      |\n",
      "| loss                | 1.62     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.742   |\n",
      "| loss_policy         | -0.742   |\n",
      "| loss_q              | 4.9      |\n",
      "| mean_episode_length | 619      |\n",
      "| mean_episode_reward | -128     |\n",
      "| norm_grads          | 44.2     |\n",
      "| norm_grads_policy   | 27.3     |\n",
      "| norm_grads_q        | 34.7     |\n",
      "| total_timesteps     | 70020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 6.25     |\n",
      "| avg_norm_grads_f    | 6.25     |\n",
      "| avg_norm_k          | 1.99     |\n",
      "| avg_norm_k_dot_g    | 7.23     |\n",
      "| entropy             | 8.73     |\n",
      "| explained_variance  | 0.206    |\n",
      "| fps                 | 246      |\n",
      "| loss                | 7.09     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.934    |\n",
      "| loss_policy         | 0.934    |\n",
      "| loss_q              | 12.5     |\n",
      "| mean_episode_length | 632      |\n",
      "| mean_episode_reward | -129     |\n",
      "| norm_grads          | 94.7     |\n",
      "| norm_grads_policy   | 15.2     |\n",
      "| norm_grads_q        | 93.5     |\n",
      "| total_timesteps     | 72020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 3.49     |\n",
      "| avg_norm_grads_f    | 3.49     |\n",
      "| avg_norm_k          | 2.35     |\n",
      "| avg_norm_k_dot_g    | 3.1      |\n",
      "| entropy             | 7.15     |\n",
      "| explained_variance  | 0.0645   |\n",
      "| fps                 | 246      |\n",
      "| loss                | 1.29     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.544    |\n",
      "| loss_policy         | 0.544    |\n",
      "| loss_q              | 1.63     |\n",
      "| mean_episode_length | 587      |\n",
      "| mean_episode_reward | -128     |\n",
      "| norm_grads          | 16.9     |\n",
      "| norm_grads_policy   | 8.26     |\n",
      "| norm_grads_q        | 14.7     |\n",
      "| total_timesteps     | 74020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.68     |\n",
      "| avg_norm_g          | 7.19     |\n",
      "| avg_norm_grads_f    | 6.07     |\n",
      "| avg_norm_k          | 2.1      |\n",
      "| avg_norm_k_dot_g    | 7.55     |\n",
      "| entropy             | 7.9      |\n",
      "| explained_variance  | -2.05    |\n",
      "| fps                 | 247      |\n",
      "| loss                | 7.82     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.11    |\n",
      "| loss_policy         | -1.11    |\n",
      "| loss_q              | 18       |\n",
      "| mean_episode_length | 558      |\n",
      "| mean_episode_reward | -122     |\n",
      "| norm_grads          | 101      |\n",
      "| norm_grads_policy   | 18.1     |\n",
      "| norm_grads_q        | 99.6     |\n",
      "| total_timesteps     | 76020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0214   |\n",
      "| avg_norm_g          | 4.19     |\n",
      "| avg_norm_grads_f    | 4.17     |\n",
      "| avg_norm_k          | 1.89     |\n",
      "| avg_norm_k_dot_g    | 4.29     |\n",
      "| entropy             | 10.4     |\n",
      "| explained_variance  | 0.168    |\n",
      "| fps                 | 247      |\n",
      "| loss                | 2.39     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.887    |\n",
      "| loss_policy         | 0.887    |\n",
      "| loss_q              | 3.21     |\n",
      "| mean_episode_length | 553      |\n",
      "| mean_episode_reward | -121     |\n",
      "| norm_grads          | 48       |\n",
      "| norm_grads_policy   | 9.93     |\n",
      "| norm_grads_q        | 47       |\n",
      "| total_timesteps     | 78020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0126   |\n",
      "| avg_norm_g          | 2.36     |\n",
      "| avg_norm_grads_f    | 2.35     |\n",
      "| avg_norm_k          | 2.29     |\n",
      "| avg_norm_k_dot_g    | 2.18     |\n",
      "| entropy             | 8        |\n",
      "| explained_variance  | 0.121    |\n",
      "| fps                 | 246      |\n",
      "| loss                | 0.626    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.422    |\n",
      "| loss_policy         | 0.422    |\n",
      "| loss_q              | 0.568    |\n",
      "| mean_episode_length | 576      |\n",
      "| mean_episode_reward | -124     |\n",
      "| norm_grads          | 3.17     |\n",
      "| norm_grads_policy   | 1.74     |\n",
      "| norm_grads_q        | 2.65     |\n",
      "| total_timesteps     | 80020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.592    |\n",
      "| avg_norm_g          | 5.58     |\n",
      "| avg_norm_grads_f    | 5.15     |\n",
      "| avg_norm_k          | 2.49     |\n",
      "| avg_norm_k_dot_g    | 5.44     |\n",
      "| entropy             | 7.55     |\n",
      "| explained_variance  | -1.26    |\n",
      "| fps                 | 245      |\n",
      "| loss                | 3.88     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.137   |\n",
      "| loss_policy         | -0.137   |\n",
      "| loss_q              | 8.19     |\n",
      "| mean_episode_length | 560      |\n",
      "| mean_episode_reward | -125     |\n",
      "| norm_grads          | 52.1     |\n",
      "| norm_grads_policy   | 15       |\n",
      "| norm_grads_q        | 49.9     |\n",
      "| total_timesteps     | 82020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.82     |\n",
      "| avg_norm_g          | 7.53     |\n",
      "| avg_norm_grads_f    | 6.42     |\n",
      "| avg_norm_k          | 1.97     |\n",
      "| avg_norm_k_dot_g    | 7.67     |\n",
      "| entropy             | 7.18     |\n",
      "| explained_variance  | -0.196   |\n",
      "| fps                 | 246      |\n",
      "| loss                | 1.54     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.32    |\n",
      "| loss_policy         | -1.32    |\n",
      "| loss_q              | 5.86     |\n",
      "| mean_episode_length | 552      |\n",
      "| mean_episode_reward | -129     |\n",
      "| norm_grads          | 40.7     |\n",
      "| norm_grads_policy   | 19.9     |\n",
      "| norm_grads_q        | 35.6     |\n",
      "| total_timesteps     | 84020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.387    |\n",
      "| avg_norm_g          | 3.68     |\n",
      "| avg_norm_grads_f    | 3.28     |\n",
      "| avg_norm_k          | 1.94     |\n",
      "| avg_norm_k_dot_g    | 5.24     |\n",
      "| entropy             | 6.25     |\n",
      "| explained_variance  | -0.466   |\n",
      "| fps                 | 245      |\n",
      "| loss                | 0.662    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.104   |\n",
      "| loss_policy         | -0.104   |\n",
      "| loss_q              | 1.66     |\n",
      "| mean_episode_length | 524      |\n",
      "| mean_episode_reward | -131     |\n",
      "| norm_grads          | 21.7     |\n",
      "| norm_grads_policy   | 13.1     |\n",
      "| norm_grads_q        | 17.3     |\n",
      "| total_timesteps     | 86020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0555   |\n",
      "| avg_norm_g          | 1.07     |\n",
      "| avg_norm_grads_f    | 1.02     |\n",
      "| avg_norm_k          | 1.96     |\n",
      "| avg_norm_k_dot_g    | 1.06     |\n",
      "| entropy             | 7.53     |\n",
      "| explained_variance  | 0.606    |\n",
      "| fps                 | 244      |\n",
      "| loss                | 0.0506   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.0759  |\n",
      "| loss_policy         | -0.0759  |\n",
      "| loss_q              | 0.404    |\n",
      "| mean_episode_length | 507      |\n",
      "| mean_episode_reward | -128     |\n",
      "| norm_grads          | 7.08     |\n",
      "| norm_grads_policy   | 3.53     |\n",
      "| norm_grads_q        | 6.14     |\n",
      "| total_timesteps     | 88020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0196   |\n",
      "| avg_norm_g          | 2.59     |\n",
      "| avg_norm_grads_f    | 2.57     |\n",
      "| avg_norm_k          | 1.86     |\n",
      "| avg_norm_k_dot_g    | 2.38     |\n",
      "| entropy             | 8.42     |\n",
      "| explained_variance  | 0.656    |\n",
      "| fps                 | 243      |\n",
      "| loss                | 0.771    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.181    |\n",
      "| loss_policy         | 0.181    |\n",
      "| loss_q              | 1.35     |\n",
      "| mean_episode_length | 525      |\n",
      "| mean_episode_reward | -126     |\n",
      "| norm_grads          | 18.5     |\n",
      "| norm_grads_policy   | 2.54     |\n",
      "| norm_grads_q        | 18.3     |\n",
      "| total_timesteps     | 90020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 3.66     |\n",
      "| avg_norm_grads_f    | 3.66     |\n",
      "| avg_norm_k          | 2.01     |\n",
      "| avg_norm_k_dot_g    | 3.59     |\n",
      "| entropy             | 9.07     |\n",
      "| explained_variance  | 0.181    |\n",
      "| fps                 | 243      |\n",
      "| loss                | 2.68     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.703    |\n",
      "| loss_policy         | 0.703    |\n",
      "| loss_q              | 4.13     |\n",
      "| mean_episode_length | 558      |\n",
      "| mean_episode_reward | -127     |\n",
      "| norm_grads          | 33.2     |\n",
      "| norm_grads_policy   | 9.2      |\n",
      "| norm_grads_q        | 31.9     |\n",
      "| total_timesteps     | 92020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.671    |\n",
      "| avg_norm_g          | 3.7      |\n",
      "| avg_norm_grads_f    | 3.26     |\n",
      "| avg_norm_k          | 1.95     |\n",
      "| avg_norm_k_dot_g    | 3.65     |\n",
      "| entropy             | 12.2     |\n",
      "| explained_variance  | 0.633    |\n",
      "| fps                 | 244      |\n",
      "| loss                | 0.0743   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.919   |\n",
      "| loss_policy         | -0.919   |\n",
      "| loss_q              | 2.23     |\n",
      "| mean_episode_length | 533      |\n",
      "| mean_episode_reward | -126     |\n",
      "| norm_grads          | 19.5     |\n",
      "| norm_grads_policy   | 10.2     |\n",
      "| norm_grads_q        | 16.6     |\n",
      "| total_timesteps     | 94020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 3.75     |\n",
      "| avg_norm_grads_f    | 3.75     |\n",
      "| avg_norm_k          | 1.87     |\n",
      "| avg_norm_k_dot_g    | 3.77     |\n",
      "| entropy             | 6.59     |\n",
      "| explained_variance  | 0.0819   |\n",
      "| fps                 | 244      |\n",
      "| loss                | 1.58     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.918    |\n",
      "| loss_policy         | 0.918    |\n",
      "| loss_q              | 1.45     |\n",
      "| mean_episode_length | 571      |\n",
      "| mean_episode_reward | -129     |\n",
      "| norm_grads          | 26.5     |\n",
      "| norm_grads_policy   | 18.9     |\n",
      "| norm_grads_q        | 18.6     |\n",
      "| total_timesteps     | 96020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.888    |\n",
      "| avg_norm_g          | 4.3      |\n",
      "| avg_norm_grads_f    | 3.74     |\n",
      "| avg_norm_k          | 1.9      |\n",
      "| avg_norm_k_dot_g    | 4.31     |\n",
      "| entropy             | 8.74     |\n",
      "| explained_variance  | 0.102    |\n",
      "| fps                 | 245      |\n",
      "| loss                | 0.876    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.01    |\n",
      "| loss_policy         | -1.01    |\n",
      "| loss_q              | 3.95     |\n",
      "| mean_episode_length | 547      |\n",
      "| mean_episode_reward | -126     |\n",
      "| norm_grads          | 45.8     |\n",
      "| norm_grads_policy   | 19.2     |\n",
      "| norm_grads_q        | 41.6     |\n",
      "| total_timesteps     | 98020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.acer.acer_simple.ACER at 0x7f70ec202990>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000) # The objective is high explained variance and high mean episode reward\n",
    "# A callback function allows the training to stop when the optimal level is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c01f04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fazer uma list ou tuple que grava os modelos e depois usar o modelo que tenha o maior mean mean.episode.reward\n",
    "# total_timesteps=100000\n",
    "# for i in range(10):\n",
    "#     model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3132acbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from stable_baselines.bench import Monitor\n",
    "# Monitor(env, None, allow_early_resets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f34475b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor.get_episode_rewards(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "918ca009",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Monitor in module stable_baselines.bench.monitor:\n",
      "\n",
      "class Monitor(gym.core.Wrapper)\n",
      " |  Monitor(env: gym.core.Env, filename: Union[str, NoneType], allow_early_resets: bool = True, reset_keywords=(), info_keywords=())\n",
      " |  \n",
      " |  A monitor wrapper for Gym environments, it is used to know the episode reward, length, time and other data.\n",
      " |  \n",
      " |  :param env: (gym.Env) The environment\n",
      " |  :param filename: (Optional[str]) the location to save a log file, can be None for no log\n",
      " |  :param allow_early_resets: (bool) allows the reset of the environment before it is done\n",
      " |  :param reset_keywords: (tuple) extra keywords for the reset call, if extra parameters are needed at reset\n",
      " |  :param info_keywords: (tuple) extra information to log, from the information return of environment.step\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Monitor\n",
      " |      gym.core.Wrapper\n",
      " |      gym.core.Env\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, env: gym.core.Env, filename: Union[str, NoneType], allow_early_resets: bool = True, reset_keywords=(), info_keywords=())\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Closes the environment\n",
      " |  \n",
      " |  get_episode_lengths(self) -> List[int]\n",
      " |      Returns the number of timesteps of all the episodes\n",
      " |      \n",
      " |      :return: ([int])\n",
      " |  \n",
      " |  get_episode_rewards(self) -> List[float]\n",
      " |      Returns the rewards of all the episodes\n",
      " |      \n",
      " |      :return: ([float])\n",
      " |  \n",
      " |  get_episode_times(self) -> List[float]\n",
      " |      Returns the runtime in seconds of all the episodes\n",
      " |      \n",
      " |      :return: ([float])\n",
      " |  \n",
      " |  get_total_steps(self) -> int\n",
      " |      Returns the total number of timesteps\n",
      " |      \n",
      " |      :return: (int)\n",
      " |  \n",
      " |  reset(self, **kwargs) -> numpy.ndarray\n",
      " |      Calls the Gym environment reset. Can only be called if the environment is over, or if allow_early_resets is True\n",
      " |      \n",
      " |      :param kwargs: Extra keywords saved for the next episode. only if defined by reset_keywords\n",
      " |      :return: (np.ndarray) the first observation of the environment\n",
      " |  \n",
      " |  step(self, action: numpy.ndarray) -> Tuple[numpy.ndarray, float, bool, Dict[Any, Any]]\n",
      " |      Step the environment with the given action\n",
      " |      \n",
      " |      :param action: (np.ndarray) the action\n",
      " |      :return: (Tuple[np.ndarray, float, bool, Dict[Any, Any]]) observation, reward, done, information\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  EXT = 'monitor.csv'\n",
      " |  \n",
      " |  file_handler = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gym.core.Wrapper:\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  compute_reward(self, achieved_goal, desired_goal, info)\n",
      " |  \n",
      " |  render(self, mode='human', **kwargs)\n",
      " |      Renders the environment.\n",
      " |      \n",
      " |      The set of supported modes varies per environment. (And some\n",
      " |      environments do not support rendering at all.) By convention,\n",
      " |      if mode is:\n",
      " |      \n",
      " |      - human: render to the current display or terminal and\n",
      " |        return nothing. Usually for human consumption.\n",
      " |      - rgb_array: Return an numpy.ndarray with shape (x, y, 3),\n",
      " |        representing RGB values for an x-by-y pixel image, suitable\n",
      " |        for turning into a video.\n",
      " |      - ansi: Return a string (str) or StringIO.StringIO containing a\n",
      " |        terminal-style text representation. The text can include newlines\n",
      " |        and ANSI escape sequences (e.g. for colors).\n",
      " |      \n",
      " |      Note:\n",
      " |          Make sure that your class's metadata 'render.modes' key includes\n",
      " |            the list of supported modes. It's recommended to call super()\n",
      " |            in implementations to use the functionality of this method.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (str): the mode to render with\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      class MyEnv(Env):\n",
      " |          metadata = {'render.modes': ['human', 'rgb_array']}\n",
      " |      \n",
      " |          def render(self, mode='human'):\n",
      " |              if mode == 'rgb_array':\n",
      " |                  return np.array(...) # return RGB frame suitable for video\n",
      " |              elif mode == 'human':\n",
      " |                  ... # pop up a window and render\n",
      " |              else:\n",
      " |                  super(MyEnv, self).render(mode=mode) # just raise an exception\n",
      " |  \n",
      " |  seed(self, seed=None)\n",
      " |      Sets the seed for this env's random number generator(s).\n",
      " |      \n",
      " |      Note:\n",
      " |          Some environments use multiple pseudorandom number generators.\n",
      " |          We want to capture all such seeds used in order to ensure that\n",
      " |          there aren't accidental correlations between multiple generators.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list<bigint>: Returns the list of seeds used in this env's random\n",
      " |            number generators. The first value in the list should be the\n",
      " |            \"main\" seed, or the value which a reproducer should pass to\n",
      " |            'seed'. Often, the main seed equals the provided 'seed', but\n",
      " |            this won't be true if seed=None, for example.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gym.core.Wrapper:\n",
      " |  \n",
      " |  class_name() from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gym.core.Wrapper:\n",
      " |  \n",
      " |  action_space\n",
      " |  \n",
      " |  metadata\n",
      " |      dict() -> new empty dictionary\n",
      " |      dict(mapping) -> new dictionary initialized from a mapping object's\n",
      " |          (key, value) pairs\n",
      " |      dict(iterable) -> new dictionary initialized as if via:\n",
      " |          d = {}\n",
      " |          for k, v in iterable:\n",
      " |              d[k] = v\n",
      " |      dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      " |          in the keyword argument list.  For example:  dict(one=1, two=2)\n",
      " |  \n",
      " |  observation_space\n",
      " |  \n",
      " |  reward_range\n",
      " |      Built-in immutable sequence.\n",
      " |      \n",
      " |      If no argument is given, the constructor returns an empty tuple.\n",
      " |      If iterable is specified the tuple is initialized from iterable's items.\n",
      " |      \n",
      " |      If the argument is a tuple, the return value is the same object.\n",
      " |  \n",
      " |  spec\n",
      " |  \n",
      " |  unwrapped\n",
      " |      Completely unwrap this env.\n",
      " |      \n",
      " |      Returns:\n",
      " |          gym.Env: The base non-wrapped gym.Env instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gym.core.Env:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Support with-statement for the environment.\n",
      " |  \n",
      " |  __exit__(self, *args)\n",
      " |      Support with-statement for the environment.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gym.core.Env:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5390cd4",
   "metadata": {},
   "source": [
    "# 3. Save and Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9bde6",
   "metadata": {},
   "source": [
    "#### Just for good practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cfa6cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30adeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ACER_LunarLander_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efca4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99d8ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ACER.load(\"ACER_LunarLander_model\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6713a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes=10\n",
    "for i in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done=False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        time.sleep(0.00003)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
